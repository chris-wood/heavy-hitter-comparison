{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "There are a wide variety of proposed solutions to the heavy hitters problem, ranging from [Poplar](https://eprint.iacr.org/2021/017.pdf) to [STAR](https://brave.com/research/files/star-ccs-2022.pdf). Conveniently, both Poplar and STAR can be viewed as a form of [VDAF](https://cfrg.github.io/draft-irtf-cfrg-vdaf/draft-irtf-cfrg-vdaf.html), or verifiable distributed aggregation function. A VDAF is a multi-party protocol between clients and one or more aggregators for computing aggregate statistics. The protocol consists of the following phases:\n",
    " \n",
    "- Sharding: Computing input shares from an individual measurement. For convenience, we also refer to this phase as the Uploading phase.\n",
    "- Preparation: Conversion and verification of input shares to output shares compatible with the aggregation function being computed.\n",
    "- Aggregation: Combining a sequence of output shares into an aggregate share.\n",
    "- Unsharding: Combining a sequence of aggregate shares into an aggregate result. For convenience, we also refer to this phase as the Finalization phase.\n",
    "\n",
    "# Protocol Costs\n",
    "\n",
    "Each of these phases has an associated cost, where cost is measured in terms of network messages, bandwidth, and computation. For convenience, let $\\mathsf{C}_{\\mathsf{phase}}^{\\mathsf{property}}(\\pi)$ be the cost of some property of a particular phrase for a VDAF $\\pi$. For example, $\\mathsf{C}_{\\mathsf{upload}}^{\\mathsf{bw}}(\\mathsf{STAR})$ is the bandwidth upload cost of $\\mathsf{STAR}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VDAF(object):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def upload_cost_bw(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def upload_cost_rounds(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def upload_cost_cpu(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def prepare_cost_bw(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def prepare_cost_rounds(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def prepare_cost_cpu(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def aggregate_cost_bw(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def aggregate_cost_rounds(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def aggregate_cost_cpu(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def finalize_cost_bw(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def finalize_cost_rounds(self):\n",
    "        raise Exception(\"implement me\")\n",
    "    def finalize_cost_cpu(self):\n",
    "        raise Exception(\"implement me\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The units of cost for rounds and bandwidth are the number of rounds and bytes, respectively. However, the computation cost units vary. They may be in terms of AES operations, scalar multipliations in a prime-order group, or some other operation. For convenience, we assume there exists a handful of standard operations for these things, and denote their cost symbolically.\n",
    "\n",
    "<!-- TODO(caw): introduce different units for computation cost that are relevant -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## STAR\n",
    "\n",
    "The STAR protocol, described in [this draft specification](https://shivankaul.com/star-spec/draft-dss-star.html), can be mapped to a VDAF in the following way.\n",
    "\n",
    "- Sharding/Uploading: Run the randomness phase of the protocol to boost the entropy of the client input measurement and send a report derived from this randomness output to the aggregator.\n",
    "- Preparation: For variants of STAR that use verifiable secret sharing (VSS) to prevent corrupt reports, the aggregator locally runs the VSS share verification algorithm to filter out invalid reports.\n",
    "- Aggregation: The aggregator locally runs the secret share recovery process using the report shares in a batch to decrypt each report and recover the heavy hitter measurement and the per-client associated auxiliary information.\n",
    "- Unsharding: This is a no-op.\n",
    "\n",
    "We assume a verison of STAR that uses verifiable secret sharing over the the ristretto255 prime-order group, and using a VOPRF configured with ristretto255 as the prime-order group. This means that each element and scalar value sent on the wire is 32 bytes. We denote the size of group elements and scalars as `ELEMENT_SIZE` and `SCALAR_SIZE`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols\n",
    "\n",
    "# TODO(caw): make these parameters for the STAR system\n",
    "ELEMENT_SIZE = 32\n",
    "SCALAR_SIZE = 32\n",
    "HEAVY_HITTER_SIZE = 64\n",
    "\n",
    "THRESHOLD, COST_VSS_VERIFY, COST_VSS_SHARE, COST_VSS_RECOVER, COST_AEAD = symbols('T VSS_VERIFY VSS_SHARE VSS_RECOVER AEAD')\n",
    "\n",
    "class STAR(VDAF):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Upload phase: Run the randomness phase of the protocol to boost \n",
    "    # the entropy of the client input measurement and send a report \n",
    "    # derived from this randomness output to the aggregator.\n",
    "    def upload_cost_bw(self):\n",
    "        def upload_cost_bw_one():\n",
    "            return ELEMENT_SIZE + \\\n",
    "                (ELEMENT_SIZE + 2*SCALAR_SIZE) + \\\n",
    "                (2*SCALAR_SIZE + HEAVY_HITTER_SIZE + (THRESHOLD * ELEMENT_SIZE)) # STAR report size\n",
    "        return upload_cost_bw_one()\n",
    "    def upload_cost_msg(self):\n",
    "        return 3 # 2 for randomness server, 1 for upload\n",
    "    def upload_cost_cpu(self):\n",
    "        # TODO(caw): make this more concrete in terms of group operations\n",
    "        return COST_VSS_SHARE + COST_AEAD\n",
    "        \n",
    "    # Prepare phase: For variants of STAR that use verifiable secret \n",
    "    # sharing (VSS) to prevent corrupt reports, the aggregator locally \n",
    "    # runs the VSS share verification algorithm to filter out invalid reports.\n",
    "    def prepare_cost_bw(self):\n",
    "        return 0\n",
    "    def prepare_cost_msg(self):\n",
    "        return 0\n",
    "    def prepare_cost_cpu(self):\n",
    "        # TODO(caw): make this more concrete in terms of group operations\n",
    "        return COST_VSS_VERIFY * THRESHOLD\n",
    "    \n",
    "    # Aggregate phase: The aggregator locally runs the secret share \n",
    "    # recovery process using the report shares in a batch to decrypt \n",
    "    # each report and recover the heavy hitter measurement and the \n",
    "    # per-client associated auxiliary information.\n",
    "    def aggregate_cost_bw(self):\n",
    "        return 0\n",
    "    def aggregate_cost_msg(self):\n",
    "        return 0\n",
    "    def aggregate_cost_cpu(self):\n",
    "        # This should be the cost of polynomial interpolation, plus the cost of report decryption\n",
    "        return COST_VSS_RECOVER + COST_AEAD\n",
    "        \n",
    "    # Finalzie phase: This phase is a no-op as the final output is already computed during the aggregate phase.\n",
    "    def finalize_cost_bw(self):\n",
    "        return 0\n",
    "    def finalize_cost_msg(self):\n",
    "        return 0\n",
    "    def finalize_cost_cpu(self):\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Per-report CPU</th>\n",
       "      <th>Per-report  Bandwidth (B)</th>\n",
       "      <th>Per-report Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Upload</th>\n",
       "      <td>AEAD + VSS_SHARE</td>\n",
       "      <td>32*T + 256</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prepare</th>\n",
       "      <td>T*VSS_VERIFY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aggregate</th>\n",
       "      <td>AEAD + VSS_RECOVER</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finalize</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Per-report CPU Per-report  Bandwidth (B)  Per-report Messages\n",
       "Upload       AEAD + VSS_SHARE                32*T + 256                    3\n",
       "Prepare          T*VSS_VERIFY                         0                    0\n",
       "Aggregate  AEAD + VSS_RECOVER                         0                    0\n",
       "Finalize                    0                         0                    0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "star = STAR()\n",
    "data = [\n",
    "    [star.upload_cost_cpu(), star.upload_cost_bw(), star.upload_cost_msg()], \n",
    "    [star.prepare_cost_cpu(), star.prepare_cost_bw(), star.prepare_cost_msg()], \n",
    "    [star.aggregate_cost_cpu(), star.aggregate_cost_bw(), star.aggregate_cost_msg()], \n",
    "    [star.finalize_cost_cpu(), star.finalize_cost_bw(), star.finalize_cost_msg()], \n",
    "]\n",
    "single_df = pd.DataFrame(data, columns=[\"Per-report CPU\", \"Per-report  Bandwidth (B)\", \"Per-report Messages\"])\n",
    "single_df.index = [\"Upload\", \"Prepare\", \"Aggregate\", \"Finalize\"]\n",
    "single_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Batch CPU</th>\n",
       "      <th>Batch Bandwidth (B)</th>\n",
       "      <th>Batch Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Upload</th>\n",
       "      <td>T*(AEAD + VSS_SHARE)</td>\n",
       "      <td>T*(32*T + 256)</td>\n",
       "      <td>3*T</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prepare</th>\n",
       "      <td>T**2*VSS_VERIFY</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aggregate</th>\n",
       "      <td>T*(AEAD + VSS_RECOVER)</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finalize</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Batch CPU Batch Bandwidth (B) Batch Messages\n",
       "Upload       T*(AEAD + VSS_SHARE)      T*(32*T + 256)            3*T\n",
       "Prepare           T**2*VSS_VERIFY                   0              0\n",
       "Aggregate  T*(AEAD + VSS_RECOVER)                   0              0\n",
       "Finalize                        0                   0              0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data = data\n",
    "for i, row in enumerate(total_data):\n",
    "    for j, col in enumerate(row):\n",
    "        total_data[i][j] *= THRESHOLD\n",
    "total_df = pd.DataFrame(data, columns=[\"Batch CPU\", \"Batch Bandwidth (B)\", \"Batch Messages\"])\n",
    "total_df.index = [\"Upload\", \"Prepare\", \"Aggregate\", \"Finalize\"]\n",
    "total_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poplar\n",
    "\n",
    "The Poplar protocol, described in [this draft specification](https://cfrg.github.io/draft-irtf-cfrg-vdaf/draft-irtf-cfrg-vdaf.html#name-poplar1), is mapped to a VDAF in the following way.\n",
    "\n",
    "- Sharding/Uploading: Clients split their measurement into shares for each aggregator and sends a report to the primary aggregator. \n",
    "- Preparation: Aggregators run an interactive protocol with the collector for evaluating an iDPF. \n",
    "- Aggregation: Aggregators locally combine output shares to yield aggregate shares.\n",
    "- Unsharding: The collector locally combines aggregate shares to yield an aggregate result. \n",
    "\n",
    "The preparation, aggregation, and unsharding phases are driven by the collector based on a set of candidate prefixes, starting from an empty set, where each sequence of phases yields a new candidate set of prefixes. As a result, this sequence of phases is run until the final heavy hitters are revealed. The number of times this sequence is run depends on the heavy hitter threshold, number of reports in a batch, and the length of each input string.\n",
    "\n",
    "For comparison, we assume a verison of Poplar that uses an iDPF over two different fields: one field for leaf nodes that has elements 32 bytes in size, and another field for inner nodes that has elements 8 bytes in size. We also assume that the heavy hitter inputs are tokenized one bit at a time (denoted by the `SKIP_FACTOR` parameter below). Finally, we assume a cryptographic seed size of 16 bytes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import symbols\n",
    "\n",
    "# TODO(caw): make these parameters for Poplar\n",
    "SKIP_FACTOR = 1\n",
    "seed_size = 16\n",
    "inner_field_encoded_size = 8\n",
    "leaf_field_encoded_size = 32\n",
    "\n",
    "# TODO(caw): make these global parameters shared by the heavy hitter systems\n",
    "# HEAVY_HITTER_SIZE = 64\n",
    "# THRESHOLD = 8\n",
    "HEAVY_HITTER_SIZE, THRESHOLD, SKIP_FACTOR = symbols('N T K')\n",
    "\n",
    "# See: https://github.com/cloudflareresearch/vdaf/blob/main/fig/bandwidth-comparison.py\n",
    "class Poplar1(VDAF):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    # Upload phase: TODO\n",
    "    def upload_cost_bw(self):\n",
    "        public_share = 0\n",
    "        leader_share = 0\n",
    "        helper_share = 0\n",
    "        \n",
    "        # IDPF - control bits\n",
    "        public_share += ((2*HEAVY_HITTER_SIZE + 7) / 8)\n",
    "\n",
    "        # IDPF - seed_cw\n",
    "        public_share += HEAVY_HITTER_SIZE * seed_size\n",
    "\n",
    "        # IDPF - w_cw - data and auth\n",
    "        #\n",
    "        # Skipping removes the correction words from skipped levels.\n",
    "        public_share += 2 * ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR) * inner_field_encoded_size # inner nodes\n",
    "        public_share += 2 * leaf_field_encoded_size # leaf nodes\n",
    "\n",
    "        # IDPF - keys\n",
    "        leader_share += seed_size\n",
    "        helper_share += seed_size\n",
    "\n",
    "        # Sketch - corr seeds\n",
    "        leader_share += seed_size\n",
    "        helper_share += seed_size\n",
    "\n",
    "        # Sketch - corr pairs\n",
    "        #\n",
    "        # Skipping removes the correction words from skipped levels.\n",
    "        leader_share += 2 * ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR) * inner_field_encoded_size # inner nodes\n",
    "        leader_share += 2 * leaf_field_encoded_size # leaf nodes\n",
    "        helper_share += 2 * ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR) * inner_field_encoded_size # inner nodes\n",
    "        helper_share += 2 * leaf_field_encoded_size # leaf nodes\n",
    "        \n",
    "        # TODO(caw): how do we want to compare leader and helper costs? Pick the larger of the two?\n",
    "        return public_share + leader_share\n",
    "        \n",
    "    def upload_cost_msg(self):\n",
    "        return 1\n",
    "    def upload_cost_cpu(self):\n",
    "        return 0 # TODO(caw): writeme\n",
    "        \n",
    "    # Prepare phase: TODO\n",
    "    def prepare_cost_bw(self):\n",
    "        aggregator_sent = 0\n",
    "\n",
    "        # round 1\n",
    "        aggregator_sent += 3 * ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR) * inner_field_encoded_size\n",
    "        aggregator_sent += 3 * leaf_field_encoded_size\n",
    "\n",
    "        # round 2\n",
    "        aggregator_sent += ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR) * inner_field_encoded_size\n",
    "        aggregator_sent += leaf_field_encoded_size\n",
    "    def prepare_cost_msg(self):\n",
    "        return 2 * ((HEAVY_HITTER_SIZE-1)/SKIP_FACTOR)\n",
    "    def prepare_cost_cpu(self):\n",
    "        return 0 # TODO(caw): writeme\n",
    "    \n",
    "    # Aggregate phase: TODO\n",
    "    def aggregate_cost_bw(self):\n",
    "        return 0\n",
    "    def aggregate_cost_msg(self):\n",
    "        return 0\n",
    "    def aggregate_cost_cpu(self):\n",
    "        return 0 # TODO(caw): cost of aggregate\n",
    "        \n",
    "    # Finalize phase: TODO\n",
    "    def finalize_cost_bw(self):\n",
    "        return 0\n",
    "    def finalize_cost_msg(self):\n",
    "        return 0\n",
    "    def finalize_cost_cpu(self):\n",
    "        return 0 # TODO(caw): cost of aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Per-report CPU</th>\n",
       "      <th>Per-report  Bandwidth (B)</th>\n",
       "      <th>Per-report Messages</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Upload</th>\n",
       "      <td>0</td>\n",
       "      <td>65*N/4 + 1287/8 + 32*(N - 1)/K</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prepare</th>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>2*(N - 1)/K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Aggregate</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finalize</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Per-report CPU       Per-report  Bandwidth (B) Per-report Messages\n",
       "Upload                  0  65*N/4 + 1287/8 + 32*(N - 1)/K                   1\n",
       "Prepare                 0                            None         2*(N - 1)/K\n",
       "Aggregate               0                               0                   0\n",
       "Finalize                0                               0                   0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "poplar = Poplar1()\n",
    "data = [\n",
    "    [poplar.upload_cost_cpu(), poplar.upload_cost_bw(), poplar.upload_cost_msg()], \n",
    "    [poplar.prepare_cost_cpu(), poplar.prepare_cost_bw(), poplar.prepare_cost_msg()], \n",
    "    [poplar.aggregate_cost_cpu(), poplar.aggregate_cost_bw(), poplar.aggregate_cost_msg()], \n",
    "    [poplar.finalize_cost_cpu(), poplar.finalize_cost_bw(), poplar.finalize_cost_msg()], \n",
    "]\n",
    "single_df = pd.DataFrame(data, columns=[\"Per-report CPU\", \"Per-report  Bandwidth (B)\", \"Per-report Messages\"])\n",
    "single_df.index = [\"Upload\", \"Prepare\", \"Aggregate\", \"Finalize\"]\n",
    "single_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Application Cost\n",
    "\n",
    "The section above discusses the cost of a single run of the protocol for collecting heavy hitters over a batch of client data. It fails to take the specifics of applications and data into account. The distribution of heavy hitters amongst a set of client reports can influence how an application chooses to run each of the protocols, and therefore has an impact on the overall cost. This is particularly important for Poplar. \n",
    "\n",
    "As an example, consider the best case scenario for Poplar, wherein the number of reports from clients matches the heavy hitter threshold, and each of the reports corresponds to the same heavy hitter value. In this case, a single run of Poplar would successfully reveal this heavy hitter to the application with minimal cost. Now consider the worst case scenario: where for a given set of reports, every possible value of heavy hitter appears $t-1$ times in the set, where $t$ is the threshold. In this case, Poplar would be maximally expensive.\n",
    "\n",
    "To further complicate matters, Poplar is designed such that client reports can be used in at most one protocol run. This means applications need to make a tradeoff between cost and utility of the protocol. They could, for example, seek to maximize the client report batch size in order to increase the probability of collecting meaningful heavy hitters, although this approach would come at increased cost. \n",
    "\n",
    "In order to meaningfully compare STAR and Poplar, we need to consider the application cost and their measurement strategy.\n",
    "\n",
    "TODO(caw): continueme - given distribution D over a set C of client reports, and probability p that the measurement yields a heavy hitter value, how big should C be?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Questions\n",
    "\n",
    "- Should the cost be parameterized per-report, or for a single run of the protocol (a batch)?\n",
    "- Should we decompose the costs of individual operations like secret sharing and iDPF evaluation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
